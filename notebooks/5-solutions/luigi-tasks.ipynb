{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From interactive programming to production ready code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from luigi.parameter import IntParameter, Parameter\n",
    "from luigi import LocalTarget, Task\n",
    "import luigi\n",
    "import json\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task No.1: Check for existing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided Docker Image already contains the dataset. This tasks just checks if everything that is needed is at the right place.\n",
    "\n",
    "*Output*: A folder containing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetExists(Task):\n",
    "    \n",
    "    dataset_name = Parameter(default=\"../../fruits\")\n",
    "\n",
    "    def output(self):\n",
    "        return LocalTarget(\"%s\" % self.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/luigi/parameter.py:261: UserWarning: Parameter \"task_process_context\" with value \"None\" is not of type string.\n",
      "  warnings.warn('Parameter \"{}\" with value \"{}\" is not of type string.'.format(param_name, param_value))\n",
      "DEBUG: Checking if DatasetExists(dataset_name=../../fruits) is complete\n",
      "INFO: Informed scheduler that task   DatasetExists_______fruits_7c796e5355   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "INFO: Worker Worker(salt=673766696, workers=1, host=dd55a1764ecf, username=root, pid=907) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 DatasetExists(dataset_name=../../fruits)\n",
      "\n",
      "Did not run any tasks\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luigi.build([DatasetExists()], local_scheduler=True, no_lock=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task No.2: Create a preprocessing configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration for the deep-learning model is essentially the Keras ImageDataGenerator. For the sake of simplicity we do not parameterize this task. But we can grasp the idea how to do it.\n",
    "\n",
    "*Input*: Nothing required <br>\n",
    "*Output*: A pickled ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configure(Task):\n",
    "    \n",
    "    config_name = Parameter(default=\"standard\")\n",
    "\n",
    "    def output(self):\n",
    "        return LocalTarget(\"configurations/%s.pickle\" % self.config_name, format=luigi.format.Nop)\n",
    "\n",
    "    def run(self):\n",
    "        import pickle\n",
    "        self.output().makedirs()\n",
    "        generator = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "        with self.output().open(\"wb\") as f:\n",
    "            pickle.dump(generator, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if Configure(config_name=standard) is complete\n",
      "INFO: Informed scheduler that task   Configure_standard_6a58a4195c   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "INFO: Worker Worker(salt=417099903, workers=1, host=dd55a1764ecf, username=root, pid=907) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 Configure(config_name=standard)\n",
      "\n",
      "Did not run any tasks\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luigi.build([Configure()], local_scheduler=True, no_lock=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task No.3: Run the baseline validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task runs the baseline validation and saves it to a file. The same as before, flexibility can be greatly enhanced by als versioning the baseline validation.\n",
    "\n",
    "*Input*: DatasetExists, Configure <br>\n",
    "*Output*: A JSON-File containing the baseline accuracy\n",
    "\n",
    "**This should be implemented by yourself ;-)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineValidation(Task):\n",
    "    \n",
    "    dataset_name = Parameter(default=\"../../fruits\")\n",
    "    config_name = Parameter(default=\"standard\")\n",
    "\n",
    "    validation_set = \"Test\"\n",
    "    img_height = 100\n",
    "    img_width = 100\n",
    "    baseline_name = \"eval.json\"\n",
    "\n",
    "    def requires(self):\n",
    "        yield DatasetExists(self.dataset_name)\n",
    "        yield Configure(self.config_name)\n",
    "\n",
    "    def output(self):\n",
    "        pass\n",
    "\n",
    "    def run(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task No.4: Train the deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task No.5 trains a Keras model and persists it to the filesystem.\n",
    "\n",
    "*Input*: DatasetExists, Configure <br>\n",
    "*Output*: A .h5 file representing the model architecture and its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def build_generator(config_path, \n",
    "                    dataset_path, \n",
    "                    data_set_type,\n",
    "                    img_height=100, img_width=100):\n",
    "    \n",
    "    with open(config_path, \"rb\") as f:\n",
    "        generator = pickle.load(f)\n",
    "    path = \"%s/%s\" % (dataset_path, data_set_type)\n",
    "    return generator.flow_from_directory(path,\n",
    "                                         target_size=(img_height, \n",
    "                                                      img_width),\n",
    "                                         color_mode='rgb')\n",
    "\n",
    "def define_model(input_shape, num_classes):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(\n",
    "        keras.layers.Conv2D(filters=4, kernel_size=(2, 2), strides=1, activation='relu', input_shape=input_shape))\n",
    "        model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(keras.layers.Conv2D(filters=4, kernel_size=(2, 2), strides=1, activation='relu'))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(keras.layers.Dropout(rate=0.25))\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(units=8, activation='relu'))\n",
    "        model.add(keras.layers.Dropout(rate=0.5))\n",
    "        model.add(keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "class TrainModel(Task):\n",
    "    \n",
    "    dataset_name = Parameter(default=\"../../fruits\")\n",
    "    config_name = Parameter(default=\"standard\")\n",
    "    model_version = IntParameter(default=1)\n",
    "    model_name = Parameter(default=\"fruits\")\n",
    "    \n",
    "    training_set = \"Training\"\n",
    "    epochs = 2\n",
    "\n",
    "    def requires(self):\n",
    "        yield DatasetExists(self.dataset_name)\n",
    "        yield Configure(self.config_name)\n",
    "\n",
    "    def output(self):\n",
    "        return LocalTarget(\"model/%d/%s.h5\" % (self.model_version, self.model_name))\n",
    "\n",
    "    def run(self):\n",
    "        self.output().makedirs()\n",
    "        dataset = self.input()[0].path\n",
    "        config = self.input()[1].path\n",
    "        training_data = build_generator(config, dataset, self.training_set)\n",
    "        input_shape = training_data.image_shape\n",
    "        num_classes = len(training_data.class_indices)\n",
    "        model = define_model(input_shape, num_classes)\n",
    "        steps_per_epoch = training_data.samples // training_data.batch_size\n",
    "        model.fit_generator(training_data,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            epochs=self.epochs,\n",
    "                            verbose=2)\n",
    "        model.save(self.output().path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if TrainModel(dataset_name=../../fruits, config_name=standard, model_version=1, model_name=fruits) is complete\n",
      "INFO: Informed scheduler that task   TrainModel_standard_______fruits_fruits_70c43a64fd   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "INFO: Worker Worker(salt=626370923, workers=1, host=dd55a1764ecf, username=root, pid=907) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 TrainModel(dataset_name=../../fruits, config_name=standard, model_version=1, model_name=fruits)\n",
      "\n",
      "Did not run any tasks\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luigi.build([TrainModel()], local_scheduler=True, no_lock=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task No.5: Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last task evaluates our model and - if it surpasses the baseline accuracy - saves the evaluation results to the filesystem. Let the task crash if the model does not perform well enough. It's worth an exception!\n",
    "\n",
    "*Input*: DatasetExists, Configure, TrainModel, BaselineValidation<br>\n",
    "*Output*: A JSON file containing the evaluation results\n",
    "\n",
    "**This should be implemented by yourself ;-)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate(Task):\n",
    "    \n",
    "    dataset_name = Parameter(default=\"../../fruits\")\n",
    "    config_name = Parameter(default=\"standard\")\n",
    "    model_version = IntParameter(default=1)\n",
    "    model_name = Parameter(default=\"fruits\")\n",
    "\n",
    "    validation_set = \"Test\"\n",
    "\n",
    "    def requires(self):\n",
    "        yield TrainModel(self.dataset_name, \n",
    "                         self.config_name,\n",
    "                         self.model_version,\n",
    "                         self.model_name)\n",
    "        yield BaselineValidation(self.dataset_name,\n",
    "                                 self.config_name)\n",
    "        yield DatasetExists(self.dataset_name)\n",
    "        yield Configure(self.config_name)\n",
    "\n",
    "    def output(self):\n",
    "        pass\n",
    "\n",
    "    def run(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise Task No.6: Deploy to TensorFlow-Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras model is performing well. Let's deploy it to TensorFlow Serving.\n",
    "\n",
    "It can be loaded with TensorFlow Serving by the following command:\n",
    "tensorflow_model_server --model_name=\"keras_model\" --model_base_path=\"serving/keras_model\"\n",
    "\n",
    "*Input*: TrainModel, Evaluate </br>\n",
    "*Output*: The TensorFlow-Graph and its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import builder\n",
    "\n",
    "class Export(Task):\n",
    "    dataset_name = Parameter(default=\"../../fruits\")\n",
    "    config_name = Parameter(default=\"standard\")\n",
    "    model_version = IntParameter(default=1)\n",
    "    model_name = Parameter(default=\"fruits\")\n",
    "\n",
    "    def requires(self):\n",
    "        yield TrainModel(self.dataset_name,\n",
    "                         self.config_name,\n",
    "                         self.model_version,\n",
    "                         self.model_name)\n",
    "\n",
    "    def output(self):\n",
    "        return LocalTarget(\"../6-models/%s/%d\" % (self.model_name,\n",
    "                                                  self.model_version))\n",
    "\n",
    "    def run(self):\n",
    "        self.output().makedirs()\n",
    "        model_path = self.input()[0].path\n",
    "        model = keras.models.load_model(model_path)\n",
    "        tensor_info_input = tf.saved_model.utils.build_tensor_info(model.input)\n",
    "        tensor_info_output = tf.saved_model.utils.build_tensor_info(model.output)\n",
    "        prediction_signature = (\n",
    "            tf.saved_model.signature_def_utils.build_signature_def(\n",
    "                inputs={'input': tensor_info_input},\n",
    "                outputs={'prediction': tensor_info_output},\n",
    "                method_name=signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "        export_path = self.output().path\n",
    "        tf_builder = builder.SavedModelBuilder(export_path)\n",
    "        with keras.backend.get_session() as sess:\n",
    "            tf_builder.add_meta_graph_and_variables(\n",
    "                sess=sess,\n",
    "                tags=[tag_constants.SERVING],\n",
    "                signature_def_map={\n",
    "                    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_signature\n",
    "                }\n",
    "            )\n",
    "            tf_builder.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if Export(dataset_name=../../fruits, config_name=standard, model_version=1, model_name=fruits) is complete\n",
      "DEBUG: Checking if TrainModel(dataset_name=../../fruits, config_name=standard, model_version=1, model_name=fruits) is complete\n",
      "INFO: Informed scheduler that task   Export_standard_______fruits_fruits_70c43a64fd   has status   PENDING\n",
      "INFO: Informed scheduler that task   TrainModel_standard_______fruits_fruits_70c43a64fd   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 1\n",
      "INFO: [pid 907] Worker Worker(salt=171444472, workers=1, host=dd55a1764ecf, username=root, pid=907) running   Export(dataset_name=../../fruits, config_name=standard, model_version=1, model_name=fruits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'../6-models/fruits/1/saved_model.pb'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [pid 907] Worker Worker(salt=171444472, workers=1, host=dd55a1764ecf, username=root, pid=907) done      Export(dataset_name=../../fruits, config_name=standard, model_version=1, model_name=fruits)\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   Export_standard_______fruits_fruits_70c43a64fd   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "INFO: Worker Worker(salt=171444472, workers=1, host=dd55a1764ecf, username=root, pid=907) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 2 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 TrainModel(dataset_name=../../fruits, config_name=standard, model_version=1, model_name=fruits)\n",
      "* 1 ran successfully:\n",
      "    - 1 Export(dataset_name=../../fruits, config_name=standard, model_version=1, model_name=fruits)\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luigi.build([Export()], local_scheduler=True, no_lock=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
